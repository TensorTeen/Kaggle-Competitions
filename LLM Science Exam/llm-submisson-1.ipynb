{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%pip install retriv -qqq\n",
    "%pip install nltk --force\n",
    "%pip install scipy --force\n",
    "%pip install numpy==1.24"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import retriv\n",
    "retriv.set_base_path(\"./\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:39:39.578331Z",
     "iopub.execute_input": "2023-09-19T17:39:39.579672Z",
     "iopub.status.idle": "2023-09-19T17:39:39.585897Z",
     "shell.execute_reply.started": "2023-09-19T17:39:39.579619Z",
     "shell.execute_reply": "2023-09-19T17:39:39.584518Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = os.listdir('/kaggle/input/wiki-20220301-en-sci')\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    df = pd.concat([df,pd.read_parquet('/kaggle/input/wiki-20220301-en-sci/'+file)])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:39:40.242782Z",
     "iopub.execute_input": "2023-09-19T17:39:40.246018Z",
     "iopub.status.idle": "2023-09-19T17:39:43.987866Z",
     "shell.execute_reply.started": "2023-09-19T17:39:40.245951Z",
     "shell.execute_reply": "2023-09-19T17:39:43.986622Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['id'] = df.index\n",
    "del df['url']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:39:43.990341Z",
     "iopub.execute_input": "2023-09-19T17:39:43.991054Z",
     "iopub.status.idle": "2023-09-19T17:39:43.998459Z",
     "shell.execute_reply.started": "2023-09-19T17:39:43.991012Z",
     "shell.execute_reply": "2023-09-19T17:39:43.997172Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "get_paras = lambda text : [p for p in text.split('\\n') if len(p.split())>4]\n",
    "df['text'] = df.text.apply(get_paras)\n",
    "df = df.explode('text')\n",
    "df = df.reset_index(drop=True)\n",
    "df['id'] = df.index"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.dropna()\n",
    "collection = df.to_dict(orient='records')    "
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from retriv import SparseRetriever\n",
    "\n",
    "# bm25 = SparseRetriever(\"Training_data\").index(collection)\n",
    "bm25 = SparseRetriever.load(\"Training_data\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bm25.search(\"Which of the following is an accurate definition of dynamic scaling in self-similar systems? </s> Dynamic scaling refers to the evolution of self-similar systems, where data obtained from snapshots\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "questions = pd.read_csv(r\"/kaggle/input/kaggle-llm-science-exam/train.csv\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:47:08.796143Z",
     "iopub.execute_input": "2023-09-19T17:47:08.796653Z",
     "iopub.status.idle": "2023-09-19T17:47:08.817039Z",
     "shell.execute_reply.started": "2023-09-19T17:47:08.796615Z",
     "shell.execute_reply": "2023-09-19T17:47:08.815790Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "questions['query'] = questions['prompt'] + \". \" + questions.A "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:47:09.244376Z",
     "iopub.execute_input": "2023-09-19T17:47:09.244830Z",
     "iopub.status.idle": "2023-09-19T17:47:09.252482Z",
     "shell.execute_reply.started": "2023-09-19T17:47:09.244795Z",
     "shell.execute_reply": "2023-09-19T17:47:09.251136Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_df = questions['query'].to_frame()\n",
    "_df['id'] = _df.index\n",
    "_df = _df.rename(columns={\"query\":\"text\"})\n",
    "_queries = _df.to_dict(orient='records')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T17:59:19.497713Z",
     "iopub.execute_input": "2023-09-19T17:59:19.500619Z",
     "iopub.status.idle": "2023-09-19T17:59:19.510723Z",
     "shell.execute_reply.started": "2023-09-19T17:59:19.500574Z",
     "shell.execute_reply": "2023-09-19T17:59:19.509508Z"
    },
    "trusted": true
   },
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "contexts = questions['query'].apply(lambda x: bm25.search(x, cutoff=5))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:02:34.186869Z",
     "iopub.execute_input": "2023-09-19T18:02:34.187377Z",
     "iopub.status.idle": "2023-09-19T18:02:39.993889Z",
     "shell.execute_reply.started": "2023-09-19T18:02:34.187333Z",
     "shell.execute_reply": "2023-09-19T18:02:39.992721Z"
    },
    "trusted": true
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "contexts = contexts.apply(lambda x:\"</s>\".join( [e['text'] for e in x]))\n",
    "questions['contexts'] = contexts"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:06:14.808808Z",
     "iopub.execute_input": "2023-09-19T18:06:14.809248Z",
     "iopub.status.idle": "2023-09-19T18:06:14.817666Z",
     "shell.execute_reply.started": "2023-09-19T18:06:14.809213Z",
     "shell.execute_reply": "2023-09-19T18:06:14.816263Z"
    },
    "trusted": true
   },
   "execution_count": 79,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = questions\n",
    "df[\"master\"] = df[\"prompt\"] + \"</s>\" + df[\"A\"] + \"</s>\" + df[\"B\"] + \"</s>\"+ df[\"C\"] + \"</s>\" + df[\"D\"] + \"</s>\" + df[\"E\"] + '</s>' + df[\"contexts\"]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:08:48.309819Z",
     "iopub.execute_input": "2023-09-19T18:08:48.310246Z",
     "iopub.status.idle": "2023-09-19T18:08:48.321761Z",
     "shell.execute_reply.started": "2023-09-19T18:08:48.310213Z",
     "shell.execute_reply": "2023-09-19T18:08:48.320461Z"
    },
    "trusted": true
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "le = {'A':0,'B':1,'C':2,'D':3,'E':4}\n",
    "df['answer_le'] = df.answer.replace(ohe)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:10:15.435739Z",
     "iopub.execute_input": "2023-09-19T18:10:15.436222Z",
     "iopub.status.idle": "2023-09-19T18:10:15.446694Z",
     "shell.execute_reply.started": "2023-09-19T18:10:15.436185Z",
     "shell.execute_reply": "2023-09-19T18:10:15.444927Z"
    },
    "trusted": true
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_questions = df.sample(150)\n",
    "test_questions = df[~(df.index.isin(train_questions.index))]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:11:14.873406Z",
     "iopub.execute_input": "2023-09-19T18:11:14.873885Z",
     "iopub.status.idle": "2023-09-19T18:11:14.882132Z",
     "shell.execute_reply.started": "2023-09-19T18:11:14.873842Z",
     "shell.execute_reply": "2023-09-19T18:11:14.880709Z"
    },
    "trusted": true
   },
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['split'] = 'train'\n",
    "df.loc[df.sample(50).index,\"split\"] = \"test\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:12:03.511426Z",
     "iopub.execute_input": "2023-09-19T18:12:03.511829Z",
     "iopub.status.idle": "2023-09-19T18:12:03.520953Z",
     "shell.execute_reply.started": "2023-09-19T18:12:03.511795Z",
     "shell.execute_reply": "2023-09-19T18:12:03.519599Z"
    },
    "trusted": true
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_parquet(\"master_train.parquet\",index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-19T18:12:37.954017Z",
     "iopub.execute_input": "2023-09-19T18:12:37.954476Z",
     "iopub.status.idle": "2023-09-19T18:12:37.986272Z",
     "shell.execute_reply.started": "2023-09-19T18:12:37.954438Z",
     "shell.execute_reply": "2023-09-19T18:12:37.985187Z"
    },
    "trusted": true
   },
   "execution_count": 91,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, LongT5EncoderModel\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "t5_encoder = LongT5EncoderModel.from_pretrained(\"google/longt5-local-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/longt5-local-base\")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(t5_encoder.parameters())"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Config:\n",
    "    def __init__(self,num_labels:int ,problem_type:str ,hidden_size:int ):\n",
    "        self.problem_type = problem_type\n",
    "        self.num_labels = num_labels\n",
    "        self.hidden_size = hidden_size\n",
    "        "
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class T5EncoderClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, hidden_states, **kwargs):\n",
    "        hidden_states = hidden_states[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "#         hidden_states = self.dropout(hidden_states)\n",
    "        print(hidden_states.shape)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.out_proj(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class T5EncoderForSequenceClassification:\n",
    "    \"\"\"\n",
    "    Use an in-memory T5Encoder to do sequence classification\"\"\"\n",
    "    def __init__(self, t5_encoder, config):\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.encoder = t5_encoder  # already initialized model\n",
    "        # either we are in eval mode, and the following code should do nothing\n",
    "        # or we are training, but we only want to fine tune the classifier head\n",
    "        # we do not want to fine-tune the encoder\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.classifier = T5EncoderClassificationHead(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=None,\n",
    "        output_attentions=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "       # return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        #print(sequence_output.shape)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + encoder_outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "        )"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config = Config(5,\"multi_label_classification\",768)\n",
    "model = T5EncoderForSequenceClassification(t5_encoder,config)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Qn : A : B : C : D : E : C1: C2 : C3 : C4 : C5"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"master\"] = df[\"prompt\"] + \"</s>\" + df[\"A\"] + \"</s>\" + df[\"B\"] + \"</s>\"+ df[\"C\"] + \"</s>\" + df[\"D\"] + \"</s>\" + df[\"E\"] + '</s>'"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
